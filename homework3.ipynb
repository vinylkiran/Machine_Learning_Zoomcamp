{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "599de296-2aec-46e2-93a9-a5860fa39ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f134908-569e-40b4-ae85-11497d8d67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data='https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07dfcf1-e232-45cd-992b-0c82490e5c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-13 17:19:58--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv.1’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2025-10-13 17:19:59 (9.35 MB/s) - ‘course_lead_scoring.csv.1’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29f9bbd-6945-4d25-81cc-4a6ff560d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('course_lead_scoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3bda77-1cc3-40ce-b9a3-987a4c149fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "189b9d27-5e3b-47a5-88b2-8842ffea6ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d03c2bf6-1e27-4c74-9aea-0dac22183333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no of null values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0429f7ea-9d2c-496b-834b-9cabfae79a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead_source', 'industry', 'employment_status', 'location']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e740e24-d86c-4fb4-bc77-1ad377673a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number_of_courses_viewed', 'annual_income', 'interaction_count',\n",
       "       'lead_score', 'converted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4693caa0-cc4c-4ba3-ab66-48ed507567e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[strings] = df[strings].fillna('NA')\n",
    "df[numeric_cols]=df[numeric_cols].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85ca2cc7-ed72-4d77-a1bc-ea92b2ed1009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source\n",
      "['paid_ads' 'social_media' 'events' 'referral' 'organic_search']\n",
      "6\n",
      "\n",
      "industry\n",
      "['NA' 'retail' 'healthcare' 'education' 'manufacturing']\n",
      "8\n",
      "\n",
      "number_of_courses_viewed\n",
      "[1 5 2 3 0]\n",
      "10\n",
      "\n",
      "annual_income\n",
      "[79450. 46992. 78796. 83843. 85012.]\n",
      "1268\n",
      "\n",
      "employment_status\n",
      "['unemployed' 'employed' 'NA' 'self_employed' 'student']\n",
      "5\n",
      "\n",
      "location\n",
      "['south_america' 'australia' 'europe' 'africa' 'middle_east']\n",
      "8\n",
      "\n",
      "interaction_count\n",
      "[4 1 3 6 2]\n",
      "12\n",
      "\n",
      "lead_score\n",
      "[0.94 0.8  0.69 0.87 0.62]\n",
      "101\n",
      "\n",
      "converted\n",
      "[1 0]\n",
      "2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Unique values in each column and number of unique values\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(df[col].unique()[:5])\n",
    "    print(df[col].nunique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d83ce01-d985-4ecd-8e4f-99123ddd26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "# What is the most frequent observation (mode) for the column industry?\n",
    "#NA\n",
    "#technology\n",
    "#healthcare \n",
    "#retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ead1870-d582-4870-81d3-6ddaf3a7e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent industry: retail\n"
     ]
    }
   ],
   "source": [
    "# Get the mode (most frequent value) of 'industry'\n",
    "most_frequent_industry = df['industry'].mode()[0]\n",
    "\n",
    "print(\"Most frequent industry:\", most_frequent_industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88c15e0e-5c70-447c-ae0c-8b9b3357e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2\n",
    "#What are the two features that have the biggest correlation?\n",
    "\n",
    "#interaction_count and lead_score\n",
    "#number_of_courses_viewed and lead_score\n",
    "#number_of_courses_viewed and interaction_count\n",
    "#annual_income and interaction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6114917-b670-46bf-8f7e-6dd149275f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          number_of_courses_viewed  annual_income  \\\n",
      "number_of_courses_viewed                  1.000000       0.009770   \n",
      "annual_income                             0.009770       1.000000   \n",
      "interaction_count                        -0.023565       0.027036   \n",
      "lead_score                               -0.004879       0.015610   \n",
      "\n",
      "                          interaction_count  lead_score  \n",
      "number_of_courses_viewed          -0.023565   -0.004879  \n",
      "annual_income                      0.027036    0.015610  \n",
      "interaction_count                  1.000000    0.009888  \n",
      "lead_score                         0.009888    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Identify numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Specify your target variable name (example: 'converted')\n",
    "target_col = 'converted'\n",
    "\n",
    "# Exclude the target variable\n",
    "numeric_features = [col for col in numeric_cols if col != target_col]\n",
    "\n",
    "# Compute the correlation matrix for numeric features only\n",
    "correlation_matrix = df[numeric_features].corr()\n",
    "\n",
    "# Display\n",
    "print(correlation_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dae5a1c-27d6-4c36-874a-b7619b0d4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the two features with the largest absolute correlation (ignoring the diagonal)\n",
    "corr_matrix_abs = correlation_matrix.abs()\n",
    "\n",
    "top_corr = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)) \\\n",
    "    .stack() \\\n",
    "    .sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd95b3d5-b616-487c-82c2-22ee1a2b72d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual_income  interaction_count    0.027036\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(top_corr[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57be2a50-f66b-436a-8991-7050b368e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Split the data\n",
    "\n",
    "# * Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "\n",
    "# * Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25,\n",
    "                                    random_state=RANDOM_SEED)\n",
    "# * Make sure that the target value `y` is not in your dataframe.\n",
    "len(df_train), len(df_val), len(df_test)\n",
    "\n",
    "# Resetting indices\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# Setting targets\n",
    "y_train = df_train[target_col].values\n",
    "y_val = df_val[target_col].values\n",
    "y_test = df_test[target_col].values\n",
    "\n",
    "del df_train[target_col], df_val[target_col], df_test[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b7b2f8-f773-419c-b14f-4b04c81d0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "#Calculate the mutual information score between y and other categorical variables in the dataset. Use the training set only.\n",
    "#Round the scores to 2 decimals using round(score, 2).import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76c79c7b-1b12-47d4-967a-5fda1ab82c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores (Training Set, Categorical Features):\n",
      "lead_source          0.04\n",
      "employment_status    0.01\n",
      "industry             0.01\n",
      "location             0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Select categorical columns from training data\n",
    "categorical_cols = df_train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Convert categorical variables to numeric (factorize for MI)\n",
    "X_train_encoded = df_train[categorical_cols].apply(lambda col: col.factorize()[0])\n",
    "\n",
    "# Compute mutual information between each categorical feature and target\n",
    "mi_scores = mutual_info_classif(X_train_encoded, y_train, discrete_features=True, random_state=42)\n",
    "\n",
    "# Create a pandas Series with feature names and MI scores\n",
    "mi_scores = pd.Series(mi_scores, index=categorical_cols).sort_values(ascending=False).round(2)\n",
    "\n",
    "# Display the results\n",
    "print(\"Mutual Information Scores (Training Set, Categorical Features):\")\n",
    "print(mi_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a696bfe-b77f-4795-9130-84812a193611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `lead_source` has the highest mutual information score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6c32d7c-cabe-4eea-b028-d59abfca9740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4\n",
    "#Now let's train a logistic regression.\n",
    "#Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "#Fit the model on the training dataset.\n",
    "#To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "#model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "#Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "#What accuracy did you get?\n",
    "#0.64\n",
    "#0.74\n",
    "#0.84\n",
    "#0.94\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2334edba-80cb-480f-829a-37150a7dd6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Identify categorical and numerical columns\n",
    "categorical_cols = df_train.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_cols = df_train.select_dtypes(include=['number']).columns\n",
    "\n",
    "# 2. One-hot encode categorical variables\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "X_train_encoded = pd.DataFrame(\n",
    "    encoder.fit_transform(df_train[categorical_cols]),\n",
    "    columns=encoder.get_feature_names_out(categorical_cols)\n",
    ")\n",
    "\n",
    "X_val_encoded = pd.DataFrame(\n",
    "    encoder.transform(df_val[categorical_cols]),\n",
    "    columns=encoder.get_feature_names_out(categorical_cols)\n",
    ")\n",
    "\n",
    "# 3. Combine numeric and encoded categorical columns\n",
    "X_train_final = pd.concat([df_train[numerical_cols].reset_index(drop=True), X_train_encoded.reset_index(drop=True)], axis=1)\n",
    "X_val_final = pd.concat([df_val[numerical_cols].reset_index(drop=True), X_val_encoded.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 4. Train logistic regression model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_final, y_train)\n",
    "\n",
    "# 5. Predict and calculate accuracy on validation set\n",
    "y_pred = model.predict(X_val_final)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# 6. Round accuracy to 2 decimals\n",
    "print(f\"Validation Accuracy: {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41ae603d-4797-44c5-a8d7-0389df22184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy : 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d899224-c56c-44b4-9d23-353ae9d5cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5\n",
    "#Let's find the least useful feature using the feature elimination technique.\n",
    "#Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "#Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "#For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "#Which of following feature has the smallest difference?\n",
    "#'industry'\n",
    "#'employment_status'\n",
    "#'lead_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afec0bdb-7bd6-47ab-8948-7adc98418ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.6996587030716723\n",
      "\n",
      "Accuracy differences after removing each feature:\n",
      "industry: 0.0000\n",
      "employment_status: 0.0034\n",
      "lead_score: -0.0068\n",
      "\n",
      "Least useful feature: lead_score\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def prepare_data(train_df, val_df, drop_feature=None):\n",
    "    # Drop a specific feature if specified\n",
    "    if drop_feature:\n",
    "        train_df = train_df.drop(columns=[drop_feature])\n",
    "        val_df = val_df.drop(columns=[drop_feature])\n",
    "    \n",
    "    categorical_cols = train_df.select_dtypes(include=['object', 'category']).columns\n",
    "    numerical_cols = train_df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    # One-hot encode categorical variables\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    X_train_encoded = pd.DataFrame(\n",
    "        encoder.fit_transform(train_df[categorical_cols]),\n",
    "        columns=encoder.get_feature_names_out(categorical_cols)\n",
    "    )\n",
    "    X_val_encoded = pd.DataFrame(\n",
    "        encoder.transform(val_df[categorical_cols]),\n",
    "        columns=encoder.get_feature_names_out(categorical_cols)\n",
    "    )\n",
    "    \n",
    "    # Combine numerical and encoded categorical columns\n",
    "    X_train_final = pd.concat([train_df[numerical_cols].reset_index(drop=True),\n",
    "                               X_train_encoded.reset_index(drop=True)], axis=1)\n",
    "    X_val_final = pd.concat([val_df[numerical_cols].reset_index(drop=True),\n",
    "                             X_val_encoded.reset_index(drop=True)], axis=1)\n",
    "    return X_train_final, X_val_final\n",
    "\n",
    "# 1. Baseline model (all features)\n",
    "X_train_full, X_val_full = prepare_data(df_train, df_val)\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_full, y_train)\n",
    "baseline_accuracy = accuracy_score(y_val, model.predict(X_val_full))\n",
    "print(\"Baseline accuracy:\", baseline_accuracy)\n",
    "\n",
    "# 2. Feature elimination\n",
    "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "diffs = {}\n",
    "\n",
    "for feature in features_to_test:\n",
    "    X_train_sub, X_val_sub = prepare_data(df_train, df_val, drop_feature=feature)\n",
    "    model.fit(X_train_sub, y_train)\n",
    "    acc = accuracy_score(y_val, model.predict(X_val_sub))\n",
    "    diffs[feature] = baseline_accuracy - acc\n",
    "\n",
    "# 3. Show results\n",
    "print(\"\\nAccuracy differences after removing each feature:\")\n",
    "for f, d in diffs.items():\n",
    "    print(f\"{f}: {d:.4f}\")\n",
    "\n",
    "# Find least useful feature\n",
    "least_useful = min(diffs, key=diffs.get)\n",
    "print(f\"\\nLeast useful feature: {least_useful}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41752e-e856-4b7a-bc35-ea975e4c88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's train a regularized logistic regression.\n",
    "#Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\n",
    "#Train models using all the features as in Q4.\n",
    "#Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "#Which of these C leads to the best accuracy on the validation set?\n",
    "\n",
    "#0.01\n",
    "#0.1\n",
    "#1\n",
    "#10\n",
    "#100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1094b1ff-f444-49ea-8290-11677a78bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracies (rounded to 3 decimals):\n",
      "C=0.01    Accuracy=0.700\n",
      "C=0.1     Accuracy=0.700\n",
      "C=1       Accuracy=0.700\n",
      "C=10      Accuracy=0.700\n",
      "C=100     Accuracy=0.700\n",
      "\n",
      "Best C: 0.01 with validation accuracy 0.700\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Reuse the encoded and combined training/validation data from Q4\n",
    "# (X_train_final, X_val_final, y_train, y_val must already be defined)\n",
    "\n",
    "# List of C values to test\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "results = []\n",
    "\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(\n",
    "        solver='liblinear',\n",
    "        penalty='l2',\n",
    "        C=C,\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_final, y_train)\n",
    "    y_pred = model.predict(X_val_final)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    results.append((C, round(acc, 3)))\n",
    "\n",
    "# Display results\n",
    "print(\"Validation Accuracies (rounded to 3 decimals):\")\n",
    "for C, acc in results:\n",
    "    print(f\"C={C:<6}  Accuracy={acc:.3f}\")\n",
    "\n",
    "# Pick the best (ties → smaller C)\n",
    "best_acc = max(a for _, a in results)\n",
    "best_candidates = [C for C, a in results if a == best_acc]\n",
    "best_C = min(best_candidates)\n",
    "\n",
    "print(f\"\\nBest C: {best_C} with validation accuracy {best_acc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
